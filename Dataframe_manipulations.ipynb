{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Row\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@432df776\n",
       "df: org.apache.spark.sql.DataFrame = [label: double, features: array<double>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[5.1, 3.5, 1.4, 0.2]|\n",
      "|  0.0|[4.9, 3.0, 1.4, 0.2]|\n",
      "|  0.0|[4.7, 3.2, 1.3, 0.2]|\n",
      "|  0.0|[4.6, 3.1, 1.5, 0.2]|\n",
      "|  0.0|[5.0, 3.6, 1.4, 0.2]|\n",
      "|  0.0|[5.4, 3.9, 1.7, 0.4]|\n",
      "|  0.0|[4.6, 3.4, 1.4, 0.3]|\n",
      "|  0.0|[5.0, 3.4, 1.5, 0.2]|\n",
      "|  0.0|[4.4, 2.9, 1.4, 0.2]|\n",
      "|  0.0|[4.9, 3.1, 1.5, 0.1]|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.linalg.Vector\n",
    "import org.apache.spark.sql.functions._ \n",
    "\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "import sqlContext.implicits._\n",
    "case class Row(label: Double, features: Array[Double])\n",
    "\n",
    "var df = sqlContext.read.parquet(\"iris.parquet\")\n",
    "    .map(row => {\n",
    "        val label = row.get(0).asInstanceOf[Double]\n",
    "        val features = row.get(1).asInstanceOf[Vector].toArray\n",
    "        Row(label, features)\n",
    "    }).toDF\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Фильтрация по признаку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|[7.0, 3.2, 4.7, 1.4]|\n",
      "|  1.0|[6.4, 3.2, 4.5, 1.5]|\n",
      "|  1.0|[6.9, 3.1, 4.9, 1.5]|\n",
      "|  1.0|[5.5, 2.3, 4.0, 1.3]|\n",
      "|  1.0|[6.5, 2.8, 4.6, 1.5]|\n",
      "|  1.0|[5.7, 2.8, 4.5, 1.3]|\n",
      "|  1.0|[6.3, 3.3, 4.7, 1.6]|\n",
      "|  1.0|[4.9, 2.4, 3.3, 1.0]|\n",
      "|  1.0|[6.6, 2.9, 4.6, 1.3]|\n",
      "|  1.0|[5.2, 2.7, 3.9, 1.4]|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter($\"label\" === 1).show(10)  // К столбцу можно обращаться: $\"colName\" или dataframe.col(\"colName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "func: org.apache.spark.sql.UserDefinedFunction = UserDefinedFunction(<function1>,IntegerType,List(DoubleType))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[5.1, 3.5, 1.4, 0.2]|\n",
      "|    1|[4.9, 3.0, 1.4, 0.2]|\n",
      "|    1|[4.7, 3.2, 1.3, 0.2]|\n",
      "|    1|[4.6, 3.1, 1.5, 0.2]|\n",
      "|    0|[5.0, 3.6, 1.4, 0.2]|\n",
      "|    0|[5.4, 3.9, 1.7, 0.4]|\n",
      "|    1|[4.6, 3.4, 1.4, 0.3]|\n",
      "|    1|[5.0, 3.4, 1.5, 0.2]|\n",
      "|    1|[4.4, 2.9, 1.4, 0.2]|\n",
      "|    1|[4.9, 3.1, 1.5, 0.1]|\n",
      "|    0|[5.4, 3.7, 1.5, 0.2]|\n",
      "|    1|[4.8, 3.4, 1.6, 0.2]|\n",
      "|    1|[4.8, 3.0, 1.4, 0.1]|\n",
      "|    1|[4.3, 3.0, 1.1, 0.1]|\n",
      "|    0|[5.8, 4.0, 1.2, 0.2]|\n",
      "|    0|[5.7, 4.4, 1.5, 0.4]|\n",
      "|    0|[5.4, 3.9, 1.3, 0.4]|\n",
      "|    0|[5.1, 3.5, 1.4, 0.3]|\n",
      "|    0|[5.7, 3.8, 1.7, 0.3]|\n",
      "|    0|[5.1, 3.8, 1.5, 0.3]|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.udf\n",
    "val func = udf( (s:Double) => if(s < 3.5) 1 else 0 )\n",
    "\n",
    "df.withColumn(\"label\",  func(df.col(\"features\").getItem(1))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[4.9, 3.0, 1.4, 0.2]|\n",
      "|  0.0|[4.7, 3.2, 1.3, 0.2]|\n",
      "|  0.0|[4.6, 3.1, 1.5, 0.2]|\n",
      "|  0.0|[4.6, 3.4, 1.4, 0.3]|\n",
      "|  0.0|[4.4, 2.9, 1.4, 0.2]|\n",
      "|  0.0|[4.9, 3.1, 1.5, 0.1]|\n",
      "|  0.0|[4.8, 3.4, 1.6, 0.2]|\n",
      "|  0.0|[4.8, 3.0, 1.4, 0.1]|\n",
      "|  0.0|[4.3, 3.0, 1.1, 0.1]|\n",
      "|  0.0|[4.6, 3.6, 1.0, 0.2]|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.col(\"features\").getItem(0) < 5).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Выборка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select($\"label\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|(features[1] / 2)|\n",
      "+-----+-----------------+\n",
      "|  0.0|             1.75|\n",
      "|  0.0|              1.5|\n",
      "|  0.0|              1.6|\n",
      "|  0.0|             1.55|\n",
      "|  0.0|              1.8|\n",
      "|  0.0|             1.95|\n",
      "|  0.0|              1.7|\n",
      "|  0.0|              1.7|\n",
      "|  0.0|             1.45|\n",
      "|  0.0|             1.55|\n",
      "+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select($\"label\", $\"features\".getItem(1) / 2).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Применение функции к признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|  LOG(features[1])|\n",
      "+------------------+\n",
      "| 1.252762968495368|\n",
      "|1.0986122886681098|\n",
      "|1.1631508098056809|\n",
      "|1.1314021114911006|\n",
      "|1.2809338454620642|\n",
      "|1.3609765531356006|\n",
      "|1.2237754316221157|\n",
      "|1.2237754316221157|\n",
      "|1.0647107369924282|\n",
      "|1.1314021114911006|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+--------------------+---------------+\n",
      "|label|            features|log(features_1)|\n",
      "+-----+--------------------+---------------+\n",
      "|  0.0|[5.1, 3.5, 1.4, 0.2]|          1.253|\n",
      "|  0.0|[4.9, 3.0, 1.4, 0.2]|          1.099|\n",
      "|  0.0|[4.7, 3.2, 1.3, 0.2]|          1.163|\n",
      "|  0.0|[4.6, 3.1, 1.5, 0.2]|          1.131|\n",
      "|  0.0|[5.0, 3.6, 1.4, 0.2]|          1.281|\n",
      "|  0.0|[5.4, 3.9, 1.7, 0.4]|          1.361|\n",
      "|  0.0|[4.6, 3.4, 1.4, 0.3]|          1.224|\n",
      "|  0.0|[5.0, 3.4, 1.5, 0.2]|          1.224|\n",
      "|  0.0|[4.4, 2.9, 1.4, 0.2]|          1.065|\n",
      "|  0.0|[4.9, 3.1, 1.5, 0.1]|          1.131|\n",
      "+-----+--------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._    // Импортируем implicit функции над колонками\n",
    "\n",
    "df.select(log($\"features\".getItem(1))).show(10)  // Логарифм от второго признака\n",
    "df.withColumn(\"log(features_1)\", round(log($\"features\".getItem(1)), 3)).show(10) // Создадим новую колонку с этим признаком\n",
    "                                                                                 // округленным до 3 знака"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SQL\n",
    "Аналогично можно манипулировать данными c помощью SQL-запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|label|feature2|\n",
      "+-----+--------+\n",
      "|  0.0|     3.5|\n",
      "|  0.0|     3.0|\n",
      "|  0.0|     3.2|\n",
      "|  0.0|     3.1|\n",
      "|  0.0|     3.6|\n",
      "+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable(\"df\") // Регистрируем таблицу\n",
    "sqlContext.sql(\"SELECT label, features[1] AS feature2 FROM df\").show(5) // Через sqlContext делаем запрос к таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|_c0|\n",
      "+---+\n",
      "| 50|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT COUNT(*) FROM df WHERE label = 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Партиционирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|[7.0, 3.2, 4.7, 1.4]|\n",
      "|  1.0|[6.4, 3.2, 4.5, 1.5]|\n",
      "|  1.0|[6.9, 3.1, 4.9, 1.5]|\n",
      "|  1.0|[5.5, 2.3, 4.0, 1.3]|\n",
      "|  1.0|[6.5, 2.8, 4.6, 1.5]|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.repartition($\"label\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Бинаризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: Array[(Int, Double)] = Array((0,0.1), (1,0.8), (2,0.3), (2,0.4), (2,0.6), (2,0.7), (3,0.5))\n",
       "dataFrame: org.apache.spark.sql.DataFrame = [label: int, feature: double]\n",
       "binarizer: org.apache.spark.ml.feature.Binarizer = binarizer_f0dff79e2751\n",
       "binarizedDataFrame: org.apache.spark.sql.DataFrame = [label: int, feature: double, binarized_feature: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----------------+\n",
      "|label|feature|binarized_feature|\n",
      "+-----+-------+-----------------+\n",
      "|0    |0.1    |0.0              |\n",
      "|1    |0.8    |1.0              |\n",
      "|2    |0.3    |0.0              |\n",
      "|2    |0.4    |0.0              |\n",
      "|2    |0.6    |1.0              |\n",
      "|2    |0.7    |1.0              |\n",
      "|3    |0.5    |1.0              |\n",
      "+-----+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.Binarizer\n",
    "\n",
    "val data = Array((0, 0.1), (1, 0.8), (2, 0.3), (2, 0.4), (2, 0.6), (2, 0.7), (3, 0.5))\n",
    "val dataFrame = sqlContext.createDataFrame(data).toDF(\"label\", \"feature\")\n",
    "\n",
    "val binarizer = new Binarizer()\n",
    "  .setInputCol(\"feature\")\n",
    "  .setOutputCol(\"binarized_feature\")\n",
    "  .setThreshold(0.4)\n",
    "\n",
    "val binarizedDataFrame = binarizer.transform(dataFrame)\n",
    "\n",
    "binarizedDataFrame.show(false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala - DL4j",
   "language": "scala",
   "name": "apache_toree_scala-dl4j"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
