{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Классификация ирисов (ml - DataFrame api)\n",
    "+ Импорт данных из hdfs\n",
    "+ Разделение выборки на обучающую и тестовую\n",
    "+ Обучение модели многоклассовой классификации с помощью логистической регрессии\n",
    "+ Оценка модели на тестовой выборке\n",
    "+ Random Forest\n",
    "\n",
    "## Импорт данных из hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data: org.apache.spark.sql.DataFrame = [label: double, features: vector]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "\n",
    "val data = sc.textFile(\"/user/supp.bda08/iris.csv\")\n",
    "    .filter(_ != \"0,1,2,3,0\")\n",
    "    .map(r => {\n",
    "        val row = r.split(\",\")\n",
    "        val vector = row.slice(0,4).map(_.toDouble)\n",
    "        val label  = row(4).toInt\n",
    "        LabeledPoint(label, Vectors.dense(vector))\n",
    "    })\n",
    "    .filter(point => {point.label != 2.0})\n",
    "    .toDF(\"label\", \"features\")\n",
    "    \n",
    "println(data.count)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Разделение выборки на обучающую и тестовую "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splited = Array([label: double, features: vector], [label: double, features: vector])\n",
       "train = [label: double, features: vector]\n",
       "test = [label: double, features: vector]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: double, features: vector]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val splited = data.randomSplit(weights = Array(0.85, 0.15), seed = 11)\n",
    "\n",
    "val train = splited(0).cache()\n",
    "val test = splited(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Обучение модели многоклассовой классификации\n",
    "Создадим модель Логистической регресии с параметрами:\n",
    "+ Кол-во итераций - 100\n",
    "+ Параметр регуляризации - 0.3\n",
    "+ ElasticNet параметр - 0.2 \n",
    "\n",
    "$$\\text{ElasticNet: }\\;\\; \\alpha \\left(\\lambda \\lVert \\mathbf w \\rVert_1 \\right) + (1 - \\alpha)\\left(\\frac{\\lambda}{2}\\lVert \\mathbf w \\rVert_2^2\\right), \\alpha \\in [0,1]$$\n",
    "\n",
    "Для того чтобы получить модель классификации с более чем 2 классами, нужно создать модель OneVsRest, задать ей классификатор и обучаться с её помощью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier: org.apache.spark.ml.classification.LogisticRegression = logreg_1fa894baf5a1\n",
       "ovr: org.apache.spark.ml.classification.OneVsRest = oneVsRest_8cd48ca2465b\n",
       "model: org.apache.spark.ml.classification.OneVsRestModel = oneVsRest_8cd48ca2465b\n",
       "preds: org.apache.spark.sql.DataFrame = [label: double, features: vector, prediction: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+----------+\n",
      "|label|         features|prediction|\n",
      "+-----+-----------------+----------+\n",
      "|  0.0|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|  0.0|[4.8,3.0,1.4,0.1]|       0.0|\n",
      "|  0.0|[5.0,3.2,1.2,0.2]|       0.0|\n",
      "|  0.0|[5.0,3.4,1.5,0.2]|       0.0|\n",
      "|  0.0|[5.3,3.7,1.5,0.2]|       0.0|\n",
      "+-----+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.{OneVsRest, LogisticRegression}\n",
    "import org.apache.spark.ml.util.MetadataUtils\n",
    "\n",
    "val classifier = new LogisticRegression() \n",
    "      .setMaxIter(100)\n",
    "      .setRegParam(0.3)\n",
    "      .setElasticNetParam(0.2)\n",
    "\n",
    "val ovr = new OneVsRest()\n",
    "ovr.setClassifier(classifier)\n",
    "\n",
    "val model = ovr.fit(train)\n",
    "\n",
    "val preds = model.transform(test)\n",
    "\n",
    "preds.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Оценка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_99c9f72449a2\n",
       "f1_score: Double = 1.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score = 1.0\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "\n",
    "val f1_score = evaluator.evaluate(preds)\n",
    "\n",
    "println(s\"f1 score = ${f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Random Forest\n",
    "Аналогично можно работать с другими моделями. Пример - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier: org.apache.spark.ml.classification.RandomForestClassifier = rfc_54335529c05d\n",
       "model: org.apache.spark.ml.classification.OneVsRestModel = oneVsRest_8cd48ca2465b\n",
       "preds: org.apache.spark.sql.DataFrame = [label: double, features: vector, prediction: double]\n",
       "f1_score: Double = 1.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score = 1.0\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "\n",
    "val classifier = new RandomForestClassifier()\n",
    "    .setNumTrees(10)\n",
    "\n",
    "ovr.setClassifier(classifier)\n",
    "\n",
    "val model = ovr.fit(train)\n",
    "\n",
    "val preds = model.transform(test)\n",
    "\n",
    "val f1_score = evaluator.evaluate(preds)\n",
    "\n",
    "println(s\"f1 score = ${f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
